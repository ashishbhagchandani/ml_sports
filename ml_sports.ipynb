{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "nba = pd.read_csv(\"data/nba_2017_br.csv\")\n",
    "nba.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_df = pd.read_csv(\"../data/nba_2017_attendance.csv\")\n",
    "endorsement_df = pd.read_csv(\"../data/nba_2017_endorsements.csv\")\n",
    "valuations_df = pd.read_csv(\"../data/nba_2017_team_valuations.csv\")\n",
    "salary_df = pd.read_csv(\"../data/nba_2017_salary.csv\")\n",
    "pie_df = pd.read_csv(\"../data/nba_2017_pie.csv\")\n",
    "plus_minus_df = pd.read_csv(\"../data/nba_2017_real_plus_minus.csv\")\n",
    "br_stats_df = pd.read_csv(\"../data/nba_2017_br.csv\")\n",
    "elo_df = pd.read_csv(\"../data/nba_2017_elo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_valuation_df =\\\n",
    "attendance_df.merge(valuations_df, how=\"inner\", on=\"TEAM\")\n",
    "attendance_valuation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML \n",
    "display(HTML(\"<style>.\\container{ width:100% !important; }</style>\"));\\sns.pairplot(attendance_valuation_df, hue=\"TEAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = attendance_valuation_df.corr()\n",
    "sns.heatmap(corr,\n",
    "xticklabels=corr.columns.values,\n",
    "yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20,15))\n",
    "ax = plt.axes()\n",
    "ax.set_title(\"NBA Team AVG Attendance vs\\Valuation in Millions: 2016-2017 Season\")\n",
    "sns.heatmap(valuations,linewidths=.5, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols('VALUE_MILLIONS ~TOTAL_MILLIONS',data=attendance_valuation_df).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y=\"VALUE_MILLIONS\", x=\"TOTAL_MILLIONS\",data=attendance_valuation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "rmse = statsmodels.tools.eval_measures.rmse(\n",
    "attendance_valuation_predictions_df[\"predicted\"],attendance_valuation_predictions_df[\"VALUE_MILLIONS\"])\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_valuation_predictions_df =attendance_valuation_df.copy()\n",
    "attendance_valuation_predictions_df[\"predicted\"] =results.predict()\n",
    "sns.lmplot(x=\"predicted\", y=\"VALUE_MILLIONS\",data=attendance_valuation_predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_housing_win_df= pd.read_csv(\"../data/nba_2017_att_val_elo_win_housing.csv\")\n",
    "val_housing_win_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df = val_housing_win_df.loc[:,[\"TOTAL_ATTENDANCE_MILLIONS\", \"ELO\", \"VALUE_MILLIONS\",\"MEDIAN_HOME_PRICE_COUNTY_MILLONS\"]]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(numerical_df))\n",
    "print(scaler.transform(numerical_df))\n",
    "MinMaxScaler(copy=True, feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=3)\n",
    "kmeans = k_means.fit(scaler.transform(numerical_df))\n",
    "val_housing_win_df['cluster'] = kmeans.labels_\n",
    "val_housing_win_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_housing_win_df.to_csv(\"../data/nba_2017_att_val_elo_win_housing_cluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"scatterplot3d\",lib.loc=\"/Library/Frameworks/R.framework/\\Versions/3.4/Resources/library\")\n",
    "team_cluster = read_csv(\"~/src/aibook/src/chapter7/data/nba_2017_att_val_elo_win_housing_cluster.csv\",+ col_types = cols(X1 = col_skip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_to_numeric = function(column){+ converted_column <- as.numeric(unlist(column))+ return(converted_column)+ }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example Route To Construct:\n",
    "https://wikimedia.org/api/rest_v1/ +\n",
    "metrics/pageviews/per-article/ +\n",
    "en.wikipedia/all-access/user/ +\n",
    "LeBron_James/daily/2015070100/2017070500 +\n",
    "\"\"\"\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import wikipedia\n",
    "BASE_URL =\\\n",
    "\"https://wikimedia.org/api/rest_v1/\\\n",
    "metrics/pageviews/per-article/en.wikipedia/all-access/user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_url(handle, period, start, end):\n",
    "\"\"\"Constructs a URL based on arguments\n",
    "Should construct the following URL:\n",
    "/LeBron_James/daily/2015070100/2017070500\n",
    "\"\"\"\n",
    "urls = [BASE_URL, handle, period, start, end]\n",
    "constructed = str.join('/', urls)\n",
    "return constructed\n",
    "def query_wikipedia_pageviews(url):\n",
    "res = requests.get(url)\n",
    "return res.json()\n",
    "def wikipedia_pageviews(handle, period, start, end):\n",
    "\"\"\"Returns JSON\"\"\"\n",
    "constructed_url = construct_url(handle, period, start,end)\n",
    "pageviews = query_wikipedia_pageviews(url=constructed_url)\n",
    "return pageviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wikipedia_df(handles):\n",
    "\"\"\"Creates a Dataframe of Pageviews\"\"\"\n",
    "pageviews = []\n",
    "timestamps = []\n",
    "names = []\n",
    "wikipedia_handles = []\n",
    "for name, handle in handles.items():\n",
    "pageviews_record = wikipedia_2016(handle)\n",
    "if pageviews_record is None:\n",
    "continue\n",
    "for record in pageviews_record['items']:\n",
    "pageviews.append(record['views'])\n",
    "timestamps.append(record['timestamp'])\n",
    "names.append(name)\n",
    "wikipedia_handles.append(handle)\n",
    "data = {\n",
    "\"names\": names,\n",
    "\"wikipedia_handles\": wikipedia_handles,\n",
    "\"pageviews\": pageviews,\n",
    "\"timestamps\": timestamps\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wikipedia_handle(raw_handle):\n",
    "\"\"\"Takes a raw handle and converts it to a wikipedia handle\"\"\"\n",
    "wikipedia_handle = raw_handle.replace(\" \", \"_\")\n",
    "return wikipedia_handle\n",
    "def create_wikipedia_nba_handle(name):\n",
    "\"\"\"Appends basketball to link\"\"\"\n",
    "url = \" \".join([name, \"(basketball)\"])\n",
    "return url\n",
    "def wikipedia_current_nba_roster():\n",
    "\"\"\"Gets all links on wikipedia current roster page\"\"\"\n",
    "links = {}\n",
    "nba = wikipedia.page(\"List_of_current_NBA_team_rosters\")\n",
    "for link in nba.links:\n",
    "links[link] = create_wikipedia_handle(link)\n",
    "return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_wikipedia_nba_handle(data=\"data/nba_2017_br.csv\"):\n",
    "\"\"\"Attempt to get the correct wikipedia handle\"\"\"\n",
    "links = wikipedia_current_nba_roster()\n",
    "nba = pd.read_csv(data)\n",
    "count = 0\n",
    "verified = {}\n",
    "guesses = {}\n",
    "for player in nba[\"Player\"].values:\n",
    "if player in links:\n",
    "print(\"Player: {player}, Link: {link} \".\\\n",
    "format(player=player,\n",
    "link=links[player]))\n",
    "print(count)\n",
    "count += 1\n",
    "verified[player] = links[player] #add wikipedia link\n",
    "else:\n",
    "print(\"NO MATCH: {player}\".format(player=player))\n",
    "guesses[player] = create_wikipedia_handle(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_wikipedia_guesses(guesses):\n",
    "\"\"\"Validate guessed wikipedia accounts\"\"\"\n",
    "verified = {}\n",
    "wrong = {}\n",
    "for name, link in guesses.items():\n",
    "try:\n",
    "page = wikipedia.page(link)\n",
    "except (wikipedia.DisambiguationError,\n",
    "wikipedia.PageError) as error:\n",
    "#try basketball suffix\n",
    "nba_handle = create_wikipedia_nba_handle(name)\n",
    "try:\n",
    "page = wikipedia.page(nba_handle)\n",
    "print(\"Initial wikipedia URL Failed:\\\n",
    "{error}\".format(error=error))\n",
    "except (wikipedia.DisambiguationError,\n",
    "wikipedia.PageError) as error:\n",
    "print(\"Second Match Failure: {error}\".\\\n",
    "format(error=error))\n",
    "wrong[name] = link\n",
    "continue\n",
    "if \"NBA\" in page.summary:\n",
    "verified[name] = link\n",
    "else:\n",
    "print(\"NO GUESS MATCH: {name}\".format(name=name))\n",
    "wrong[name] = link\n",
    "return verified, wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_wikipedia_handles(data=\"data/nba_2017_br.csv\"):\n",
    "\"\"\"Clean Handles\"\"\"\n",
    "verified, guesses = guess_wikipedia_nba_handle(data=data)\n",
    "verified_cleaned, wrong = validate_wikipedia_guesses(guesses)\n",
    "print(\"WRONG Matches: {wrong}\".format(wrong=wrong))\n",
    "handles = {**verified, **verified_cleaned}\n",
    "return handles\n",
    "def nba_wikipedia_dataframe(data=\"data/nba_2017_br.csv\"):\n",
    "handles = clean_wikipedia_handles(data=data)\n",
    "df = create_wikipedia_df(handles)\n",
    "return df\n",
    "def create_wikipedia_csv(data=\"data/nba_2017_br.csv\"):\n",
    "df = nba_wikipedia_dataframe(data=data)\n",
    "df.to_csv(\"data/wikipedia_nba.csv\")\n",
    "if __name__ == \"__main__\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import twitter\n",
    "from . import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from twitter.error import TwitterError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_handler():\n",
    "\"\"\"Creates connection to Twitter API\"\"\"\n",
    "api = twitter.Api(consumer_key=config.CONSUMER_KEY,\n",
    "consumer_secret=config.CONSUMER_SECRET,\n",
    "access_token_key=config.ACCESS_TOKEN_KEY,\n",
    "access_token_secret=config.ACCESS_TOKEN_SECRET)\n",
    "return api\n",
    "def tweets_by_user(api, user, count=200):\n",
    "\"\"\"Grabs the \"n\" number of tweets. Defaults to 200\"\"\"\n",
    "tweets = api.GetUserTimeline(screen_name=user, count=count)\n",
    "return tweets\n",
    "def stats_to_df(tweets):\n",
    "\"\"\"Takes twitter stats and converts them to a dataframe\"\"\"\n",
    "records = []\n",
    "for tweet in tweets:\n",
    "records.append({\"created_at\":tweet.created_at,\n",
    "\"screen_name\":tweet.user.screen_name,\n",
    "\"retweet_count\":tweet.retweet_count,\n",
    "\"favorite_count\":tweet.favorite_count})\n",
    "df = pd.DataFrame(data=records)\n",
    "return df\n",
    "def stats_df(user):\n",
    "\"\"\"Returns a dataframe of stats\"\"\"\n",
    "api = api_handler()\n",
    "tweets = tweets_by_user(api, user)\n",
    "df = stats_to_df(tweets)\n",
    "return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = stats_df(user=\"KingJames\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_handles(sleep=.5,data=\"data/twitter_nba_combined.csv\"):\n",
    "\"\"\"yield handles\"\"\"\n",
    "nba = pd.read_csv(data)\n",
    "for handle in nba[\"twitter_handle\"]:\n",
    "time.sleep(sleep) #Avoid throttling in twitter api\n",
    "try:\n",
    "df = stats_df(handle)\n",
    "except TwitterError as error:\n",
    "print(\"Error {handle} and error msg {error}\".format(\n",
    "handle=handle,error=error))\n",
    "df = None\n",
    "yield df\n",
    "def median_engagement(data=\"data/twitter_nba_combined.csv\"):\n",
    "\"\"\"Median engagement on twitter\"\"\"\n",
    "favorite_count = []\n",
    "retweet_count = []\n",
    "nba = pd.read_csv(data)\n",
    "for record in twitter_handles(data=data):\n",
    "print(record)\n",
    "#None records stored as Nan value\n",
    "if record is None:\n",
    "print(\"NO RECORD: {record}\".format(record=record))\n",
    "favorite_count.append(np.nan)\n",
    "retweet_count.append(np.nan)\n",
    "continue\n",
    "try:\n",
    "favorite_count.append(record['favorite_count'].median())\n",
    "retweet_count.append(record[\"retweet_count\"].median())\n",
    "except KeyError as error:\n",
    "print(\"No values found to append {error}\".\\\n",
    "format(error=error))\n",
    "favorite_count.append(np.nan)\n",
    "retweet_count.append(np.nan)\n",
    "print(\"Creating DF\")\n",
    "nba['twitter_favorite_count'] = favorite_count\n",
    "nba['twitter_retweet_count'] = retweet_count\n",
    "return nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_twitter_csv(data=\"data/nba_2016_2017_wikipedia.csv\"):\n",
    "nba = median_engagement(data)\n",
    "nba.to_csv(\"data/nba_2016_2017_wikipedia_twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "color = sns.color_palette()\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container\\\n",
    "{ width:100% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "<IPython.core.display.HTML object>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "color = sns.color_palette()\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container\\{ width:100% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "<IPython.core.display.HTML object>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_players_df = br_stats_df.copy()\n",
    "nba_players_df.rename(\n",
    "columns={'Player': 'PLAYER','Pos':'POSITION','Tm': \"TEAM\", 'Age': 'AGE', \"PS/G\": \"POINTS\"}, inplace=True)\n",
    "nba_players_df.drop([\"G\", \"GS\", \"TEAM\"],inplace=True, axis=1)\n",
    "nba_players_df =nba_players_df.merge(plus_minus_df, how=\"inner\", on=\"PLAYER\")\n",
    "pie_df_subset = pie_df[[\"PLAYER\", \"PIE\",\"PACE\", \"W\"]].copy()\n",
    "nba_players_df = nba_players_df.merge(pie_df_subset, how=\"inner\", on=\"PLAYER\")\n",
    "salary_df.rename(columns={'NAME': 'PLAYER'}, inplace=True)salary_df[\"SALARY_MILLIONS\"] =\\\n",
    "round(salary_df[\"SALARY\"]/1000000, 2)salary_df.drop([\"POSITION\",\"TEAM\", \"SALARY\"],inplace=True, axis=1)\n",
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = list(set(\n",
    "nba_players_df[\"PLAYER\"].values.tolist()) â€“\n",
    "set(salary_df[\"PLAYER\"].values.tolist()))\n",
    "len(diff)\n",
    "nba_players_with_salary_df =\\nba_players_df.merge(salary_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_players_with_salary_df.columns\n",
    "len(nba_players_with_salary_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = pd.read_csv(\"../data/nba_2017_player_wikipedia.csv\")\n",
    "wiki_df.rename(columns=\\{'names': 'PLAYER', \"pageviews\": \"PAGEVIEWS\"}, inplace=True)\n",
    "median_wiki_df = wiki_df.groupby(\"PLAYER\").median()\n",
    "median_wiki_df_small = median_wiki_df[[\"PAGEVIEWS\"]]median_wiki_df_small.reset_index(level=0, inplace=True);median_wiki_df_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv(\"../data/nba_2017_twitter_players.csv\")\n",
    "nba_players_with_salary_wiki_twitter_df=\\nba_players_with_salary_wiki_df.merge(twitter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nba_players_with_salary_wiki_twitter_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20,15))\n",
    "ax = plt.axes()\n",
    "ax.set_title(\"NBA Player Correlation Heatmap\")\n",
    "corr = nba_players_with_salary_wiki_twitter_df.corr()\n",
    "sns.heatmap(corr,\n",
    "xticklabels=corr.columns.values,\n",
    "yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_df =\\nba_players_with_salary_wiki_twitter_df.loc[:,\\\n",
    "[\"AGE\", \"TRB\", \"AST\", \"STL\", \"TOV\", \"BLK\", \"PF\", \"POINTS\",\\\n",
    "\"MPG\", \"WINS_RPM\", \"W\", \"SALARY_MILLIONS\", \"PAGEVIEWS\", \\\n",
    "\"TWITTER_FAVORITE_COUNT\"]].dropna()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(numerical_df))\n",
    "print(scaler.transform(numerical_df))\n",
    "MinMaxScaler(copy=True, feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=5)\n",
    "kmeans = k_means.fit(scaler.transform(numerical_df))\n",
    "nba_players_with_salary_wiki_twitter_df['cluster'] = kmeans.labels_\n",
    "nba_players_with_salary_wiki_twitter_df.to_csv(\"../data/nba_2017_players_social_with_clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_players_with_salary_wiki_twitter_df.to_csv(\"../data/nba_2017_players_social_with_clusters.csv\")\n",
    "endorsements = pd.read_csv(\"../data/nba_2017_endorsement_full_stats.csv\")\n",
    "plt.subplots(figsize=(20,15))\n",
    "ax = plt.axes()\n",
    "ax.set_title(\"NBA Player Endorsement, \\Social Power, On-Court Performance, \\Team Valuation Correlation Heatmap: 2016-2017 Season\")\n",
    "corr = endorsements.corr()\n",
    "sns.heatmap(corr,\n",
    "xticklabels=corr.columns.values,\n",
    "yticklabels=corr.columns.values, cmap=\"copper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "plt.subplots(figsize=(20,15))\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "norm = LogNorm()\n",
    "ax = plt.axes()\n",
    "grid = endorsements.select_dtypes([np.number])\n",
    "ax.set_title(\"NBA Player Endorsement,\\Social Power, On-Court Performance,\\\n",
    "Team Valuation Heatmap: 2016-2017 Season\")sns.heatmap(grid,annot=True,\n",
    "yticklabels=endorsements[\"PLAYER\"],fmt='g',cmap=\"Accent\", cbar=False, norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
